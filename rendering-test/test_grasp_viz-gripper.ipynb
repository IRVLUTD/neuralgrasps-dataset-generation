{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a858a426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pybullet as p\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52854cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grasp_pc import set_pose_dofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d406ace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3cb32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"/root/data/output_dataset\"\n",
    "\n",
    "refined_dir = \"refined_grasps\"\n",
    "\n",
    "object_model_name = \"003_cracker_box_google_16k_textured_scale_1000\"\n",
    "\n",
    "# gripper_name = \"fetch_gripper\"\n",
    "# gripper_name = \"Barrett\"\n",
    "# gripper_name = \"HumanHand\"\n",
    "gripper_name = \"panda_grasp\"\n",
    "\n",
    "grasps_fpath = os.path.join(\n",
    "    dataset_dir,\n",
    "    refined_dir, f\"refined_{object_model_name}-{gripper_name}.json\")\n",
    "\n",
    "urdf_dir = '../prepare-graspit-urdf/urdf/'\n",
    "\n",
    "\n",
    "# images_dir = './images/' + gripper_name\n",
    "images_dir = os.path.join(dataset_dir, object_model_name, \"images\", gripper_name)\n",
    "\n",
    "if not os.path.isdir(images_dir):\n",
    "    os.makedirs(images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eb5cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ca2b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camera related stuff\n",
    "\n",
    "width = 400\n",
    "height = 400\n",
    "fov = 60\n",
    "aspect = width / height\n",
    "near = 0.02\n",
    "far = 1\n",
    "\n",
    "view_matrix = p.computeViewMatrix([0, 0, 0.5], [0, 0, 0], [1, 0, 0])\n",
    "projection_matrix = p.computeProjectionMatrixFOV(fov, aspect, near, far)\n",
    "\n",
    "cam_target_pos = [-0.97, 0.21, -0.33]\n",
    "distance = 1.80\n",
    "cam_pitch = -23.80\n",
    "cam_yaw = 74.0\n",
    "cam_roll = 0\n",
    "up_axis = 2 # 1 for Y-axis, 2 for Z-axis\n",
    "\n",
    "view_matrix_2 = p.computeViewMatrixFromYawPitchRoll(\n",
    "    cam_target_pos,\n",
    "    distance,\n",
    "    cam_yaw,\n",
    "    cam_pitch,\n",
    "    cam_roll,\n",
    "    2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbe78e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gripper URDF Loading part\n",
    "\n",
    "if gripper_name == \"fetch_gripper\":\n",
    "    gripper_urdf = \"fetch_gripper/fetch_gripper.urdf\"\n",
    "elif gripper_name == \"Barrett\":\n",
    "    gripper_urdf = \"Barrett/Barrett.urdf\"\n",
    "elif gripper_name == \"HumanHand\":\n",
    "    gripper_urdf = \"HumanHand/HumanHand.urdf\"\n",
    "elif gripper_name == \"Allegro\":\n",
    "    gripper_urdf = \"Allegro/allegro_hand_description_right.urdf\"\n",
    "elif gripper_name == \"panda_grasp\":\n",
    "    gripper_urdf = \"franka_panda/panda_arm.urdf\"\n",
    "\n",
    "gripper_urdf_file = os.path.join(urdf_dir, gripper_urdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a63464d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb968c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.connect(p.GUI) # with GUI, useful to see final result\n",
    "# pybullet.connect(pybullet.DIRECT) # without GUI, useful when coding and trying out pybullet functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c774e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c493a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grasps_fpath = \"../output_grasps/003_cracker_box_google_16k_textured_scale_1000-HumanHand.json\"\n",
    "# grasps_fpath = \"../output_grasps/003_cracker_box_google_16k_textured_scale_1000-Barrett.json\"\n",
    "# grasps_fpath = \"../output_grasps/003_cracker_box_google_16k_textured_scale_1000-fetch_gripper.json\"\n",
    "# grasps_fpath = \"../output_grasps_old/mano/glass.json\"\n",
    "# grasps_fpath = \"/root/data/output_grasps/sampled-num100_003_cracker_box_google_16k_textured_scale_1000.0-fetch_gripper.json\"\n",
    "\n",
    "# IGNORE ABOVE commnted out code\n",
    "\n",
    "with open(grasps_fpath, \"r\") as gf:\n",
    "    grasp_data = json.load(gf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75244c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 = \"/output_dataset/refined_grasps/refined_003_cracker_box_google_16k_textured_scale_1000-fetch_gripper.json\"\n",
    "# f2 = \"output_grasps/refined_grasps/refined_003_cracker_box_google_16k_textured_scale_1000-fetch_gripper.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d658bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Object\n",
    "# object_urdf_file = os.path.join(args.obj_urdf_dir, model + \".urdf\")\n",
    "obj_id = p.loadURDF(\"./003_cracker_box_custom.urdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8151272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grasps = grasp_data['grasps']\n",
    "robo_id = p.loadURDF(gripper_urdf_file)\n",
    "for idx, info in enumerate(grasps):\n",
    "    full_pose = info['pose']\n",
    "    pos = full_pose[:3]\n",
    "    orn = full_pose[3:]\n",
    "    dofs = info['dofs']\n",
    "    # tmp = p.loadURDF(gripper_urdf_file, basePosition=pos, baseOrientation=orn)\n",
    "    set_pose_dofs(gripper_name, robo_id, full_pose, dofs)\n",
    "    # w,h,img_rgb,img_dep,img_seg = p.getCameraImage(width, height, view_matrix_2, projection_matrix)\n",
    "    # img = np.reshape(img_rgb, (w,h,4))\n",
    "    img_fname = f'{gripper_name}-{object_model_name[:-20]}-refined_gnum_{idx}.png'\n",
    "    # imageio.imwrite(os.path.join(images_dir, img_fname), img)\n",
    "    # img_fname = f'img_graspnum_{idx}.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1407ac78",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.isNumpyEnabled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0913fb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 'ninad\\\n",
    "adad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10793d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### For GUI Mode\n",
    "# # w,h,img_rgb,img_dep,img_seg = pybullet.getCameraImage(900,900)\n",
    "# w,h,img_rgb,img_dep,img_seg = p.getCameraImage(width, height, view_matrix_2, projection_matrix)\n",
    "# img = np.reshape(img_rgb, (w,h,4))\n",
    "# imageio.imwrite(f'./images/sample_gripper_viz_refined_{object_model_name}-{gripper_name}.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd987d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a8ded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### For Direct MODE\n",
    "# viewMat = pybullet.computeViewMatrixFromYawPitchRoll([-0.38,0.32,-0.34], 1.0, 50, -35, 0, 1)\n",
    "# w,h,img_rgb,img_dep,img_seg = pybullet.getCameraImage(900,900, viewMat)\n",
    "# img = np.reshape(img_rgb, (w,h,4))\n",
    "# imageio.imwrite('./sample_viz_1.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7083994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246af5dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445320b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fff4308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac4db7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1969dd59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9f48ae50c07d5dbd817adfe21b16a532b1390446f05a7aa79fce1840801d45fb"
  },
  "kernelspec": {
   "display_name": "Python [conda env:pybullet] *",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
